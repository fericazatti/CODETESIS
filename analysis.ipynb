{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis de los resultados del procesamiento\n",
    "### Proceso implementado en este notebook:\n",
    "1. Importar librerias y definir variables\n",
    "\n",
    "2. Lectura de los archivos binarios que contienen el procesamiento de los sujetos\n",
    "\n",
    "3. Estimacion del estadistico:\n",
    "    - hrr: hfo resection ratio\n",
    "    - Esta variable define que tan contenida esta el area definida como hfo dentro del area de reseccion \n",
    "    \n",
    "4. Modelo de regresion logistica Outcome vs hrr\n",
    "    - la variable outcome es cualitativa pero se conierte a cuantitativa  bajo el siguiente criterio:\n",
    "        - outocme S => 1\n",
    "        - outcome F => 0\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar librerias y definir variables/constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "from src.utils.read_data_from_bids import read_four_subjects\n",
    "from src.utils.plots.hfo_plots import *\n",
    "from src.utils.analysis_utils import organize_results\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score \n",
    "from scipy.special import expit, logit\n",
    "\n",
    "from src.utils.plots.hfo_plots import regression_plot\n",
    "\n",
    "# Configuración de rutas y processed_data_directorys\n",
    "processed_data_directory = \"data/processed\"\n",
    "results_directory = \"data/results\"\n",
    "\n",
    "kwargs_bids = {\n",
    "    'dataset':'data/bids/ds004100',\n",
    "    'datatype':'ieeg',\n",
    "    'task':'interictal',\n",
    "    'acquisition':'seeg',\n",
    "    'run':'01'\n",
    "    } "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lectura de los archivos binarios .pickle\n",
    "Contienen el resultado del procesamiento mediante el algoritmo de detección de hfo. \n",
    "Un dataset de xarray por sujeto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files = os.listdir(processed_data_directory)\n",
    "\n",
    "datasets = []\n",
    "for archivo in files:\n",
    "    if archivo.endswith(\".pickle\"):\n",
    "        ruta_archivo = os.path.join(processed_data_directory, archivo)\n",
    "\n",
    "        with open(ruta_archivo, \"rb\") as file:\n",
    "            data = pickle.load(file)\n",
    "    datasets.append(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cálculo del estadistico a partir del resultado de procesamiento\n",
    "Se crea una nueva base de datos única para almacenar el valor del estadistico. \n",
    "Por cada combinación de parametros del algoritmo de detección de Hfo se obtiene un conjunto de valores -> uno por sujeto. \n",
    "\n",
    "1. hrr -> hfo resection ratio: es un valor que estima el grado de superposción que existe entre el los electrodos etiquetados con alto contenido de Hfo y los electrodos que efectivamente fueron resecados/ablacionados durante la cirugía"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "# Define las coordenadas vacías\n",
    "data['statisicians'] = []\n",
    "data['algorithm_params'] = []\n",
    "\n",
    "# Crea un objeto Dataset vacío con las coordenadas especificadas\n",
    "ds = xr.Dataset(data)\n",
    "\n",
    "#asignacion de coordenadas\n",
    "ds = ds.assign_coords(statisicians = ['hrr', 'outcome'])\n",
    "\n",
    "subject_dataset = datasets[0]\n",
    "for element in subject_dataset:\n",
    "    new_param = element\n",
    "    ds = ds.assign_coords(algorithm_params=ds['algorithm_params'].values.tolist() + [new_param])\n",
    "\n",
    "\n",
    "\n",
    "for subject_dataset in datasets:\n",
    "    \n",
    "    subject_id = subject_dataset.attrs['his_id']\n",
    "    raw, channels = read_four_subjects([subject_id.replace('sub-', '')] ,**kwargs_bids)\n",
    "    \n",
    "    hrr_list = []\n",
    "    outcomes = []\n",
    "\n",
    "    for element in subject_dataset:\n",
    "        \n",
    "        df = subject_dataset[element].to_pandas().T.reset_index()\n",
    "        df = df.drop(df[df['colors'].isna()].index)\n",
    "        for bad in raw[0].info['bads']:\n",
    "            df = df.drop(df[df['ch_split'] == bad].index)    \n",
    "\n",
    "        condicion = df['status'].isin(['resect', 'resect,soz'])\n",
    "        filtrado = df[condicion]\n",
    "        contadores = filtrado['status'].value_counts()\n",
    "\n",
    "        resection_size = contadores.sum()\n",
    "        resection_size = round(resection_size/2) \n",
    "        \n",
    "        hfo_region = df.sort_values('counts', ascending=False).head(resection_size)\n",
    "        condicion = hfo_region['status'].isin(['resect', 'resect,soz'])\n",
    "        filtrado = hfo_region[condicion]\n",
    "        contadores = filtrado['status'].value_counts()\n",
    "\n",
    "        hfo_in_resection = contadores.sum()\n",
    "\n",
    "        #hrr = round((hfo_in_resection/resection_size),2) + np.random.random() * 0.1 - 0.05#hfo resection ratio\n",
    "        hrr = round((hfo_in_resection/resection_size),2)\n",
    "        hrr_list.append(hrr)\n",
    "                \n",
    "        if subject_dataset.attrs['outcome'] == 'S':\n",
    "            outcomes.append(1)\n",
    "        else:\n",
    "            outcomes.append(0)\n",
    "\n",
    "    fusion = list(zip(hrr_list, outcomes))\n",
    "    fusion_lista = [list(fila) for fila in fusion]\n",
    "\n",
    "    ds[subject_dataset.attrs['his_id']] = xr.DataArray(fusion_lista, dims=('algorithm_params', 'statisicians'))\n",
    "    \n",
    "    df_process = organize_results(datasets)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Se reestructuran los datos en un dataframe de pandas que combina los valores de hrr de cada paciente con el resto de caracteristicas generales por paciente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process = organize_results(datasets)\n",
    "\n",
    "df_decode_detect = pd.DataFrame({'name':[], 'combination':[]})\n",
    "\n",
    "for i, element in enumerate(ds.coords[\"algorithm_params\"].values):\n",
    "    df = ds.sel(algorithm_params = element).to_pandas().T\n",
    "    df_drop = df.drop(\"algorithm_params\")\n",
    "    \n",
    "    df_process = df_process.join(df_drop['hrr']).rename(columns={'hrr': f'hfo_detect_C{i+1}'})\n",
    "    df_decode_detect = df_decode_detect.append({'name': f'hfo_detect_C{i+1}', 'combination': element}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process.head(6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisis de los resultados de hrr\n",
    "- Se realiza por cada conjunto de hrr (un conjunto por combinacion de parametros) un modelo de regresión logistica para evaluar posteriormente sus caracteristicas\n",
    "- Por cada modelo de regresión logistica se obtienen parametros que evaluan el rendimiento del clasificador:\n",
    "    1. accuarcy: exactitud global del clasificador\n",
    "    2. f1-score: surge de la combinación de la sensibilidad y precisición del modelo\n",
    "    3. AUC: área bajo la curva de la curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = {\n",
    "    'combination_name': [],\n",
    "    'band_width':[],\n",
    "    'window_width':[],\n",
    "    'accuracy': [],    \n",
    "    'f1-score': [],\n",
    "    'AUC': []\n",
    "}\n",
    "for value in df_decode_detect.iterrows():\n",
    "    value = value[1]\n",
    "    \n",
    "    df = ds.sel(algorithm_params = value['combination']).to_pandas().T\n",
    "    df_drop = df.drop(\"algorithm_params\")\n",
    "    \n",
    "    train = df_drop\n",
    "    # definiendo input y output\n",
    "    X_train = np.array(train['hrr']).reshape((-1, 1))\n",
    "    Y_train = np.array(train['outcome'])\n",
    "    Y_train = Y_train.astype(int)\n",
    "\n",
    "    # creando modelo\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred = model.predict(X_train)\n",
    "    report_dict = classification_report(Y_train, Y_pred, output_dict=True)\n",
    "    \n",
    "    #AUC calculo\n",
    "    y_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(Y_train, y_pred_proba)\n",
    "    auc = roc_auc_score(Y_train, y_pred_proba)   \n",
    "        \n",
    "    #agregar valores\n",
    "    df_results['combination_name'].append(value['name'])\n",
    "    df_results['band_width'].append(None)\n",
    "    df_results['window_width'].append(None)\n",
    "    df_results['accuracy'].append(report_dict['accuracy'])\n",
    "    df_results['f1-score'].append(report_dict['1']['f1-score'])\n",
    "    df_results['AUC'].append(auc)\n",
    "    \n",
    "df_results = pd.DataFrame(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producto = df_results['accuracy'] * df_results['f1-score']\n",
    "delete_repeat = set(producto)\n",
    "ordered = sorted(list(delete_repeat))\n",
    "maximos = ordered[-3:]\n",
    "indices_maximo = []\n",
    "for maximo in maximos:\n",
    "    indices_maximo.append(np.where(producto == maximo)[0].tolist())\n",
    "\n",
    "for row in indices_maximo:\n",
    "    for maximo in row:\n",
    "        \n",
    "        name = df_results.iloc[maximo]['combination_name']\n",
    "        combination = df_decode_detect.loc[df_decode_detect['name'] == name]['combination']\n",
    "        \n",
    "        df = ds.sel(algorithm_params = combination.iloc[0]).to_pandas().T\n",
    "        df_drop = df.drop(\"algorithm_params\")\n",
    "        train = df_drop\n",
    "        \n",
    "        regression_plot(train, combination)\n",
    "        \n",
    "        # definiendo input y output\n",
    "        X_train = np.array(train['hrr']).reshape((-1, 1))                \n",
    "        Y_pred = model.predict(X_train)\n",
    "        print(classification_report(Y_train, Y_pred)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
